"""
Multi-stage LLM extraction prompts for Auralis.

Stage 1: Per-page extraction with simple 3-key JSON output
Stage 2: Batch consolidation into structured Company and Products objects
"""

import json
import hashlib
from typing import Dict, Any, List, Optional
from datetime import datetime

from app.core.config import settings


# Token estimation: ~4 chars per token for English text
CHARS_PER_TOKEN = 4


class TokenCounter:
    """Utility for counting tokens in text."""
    
    @staticmethod
    def estimate_tokens(text: str) -> int:
        """Estimate token count using character-based heuristic."""
        # More accurate estimation considering JSON structure
        # JSON has more punctuation/structure than plain text
        json_overhead = 1.2 if '{' in text or '[' in text else 1.0
        return int(len(text) / CHARS_PER_TOKEN * json_overhead)
    
    @staticmethod
    def truncate_to_tokens(text: str, max_tokens: int) -> str:
        """Truncate text to approximate token limit."""
        max_chars = int(max_tokens * CHARS_PER_TOKEN * 0.9)  # Safety margin
        if len(text) <= max_chars:
            return text
        
        # Try to truncate at sentence boundaries
        truncated = text[:max_chars]
        last_sentence = max(
            truncated.rfind('.'),
            truncated.rfind('!'),
            truncated.rfind('?'),
            truncated.rfind('\n\n')
        )
        
        if last_sentence > max_chars * 0.8:  # If we found a good break point
            return truncated[:last_sentence + 1]
        else:
            return truncated + "..."


class MultiStageExtractor:
    """Multi-stage LLM extraction system."""
    
    def __init__(self):
        pass
    
    # Note: All entity IDs are generated by the normalizer using natural keys
    # No need for manual ID generation in the extraction process
    
    def build_stage1_prompt(
        self,
        text: str,
        page_type: str,
        competitor: str,
        url: str
    ) -> str:
        """Build Stage 1 extraction prompt."""
        
        # Truncate text to fit within token budget
        prompt_overhead = 1500  # Estimated tokens for instructions
        max_text_tokens = (settings.EXTRACTOR_MAX_TEXT_CHARS // CHARS_PER_TOKEN) - prompt_overhead
        truncated_text = TokenCounter.truncate_to_tokens(text, max_text_tokens)
        
        prompt = f"""
You are an information extractor. Read the given webpage text and return JSON with EXACTLY three top-level keys:
  - "products": map <Exact Product Name> → {{"text": "<newline-bulleted explanation>"}}
  - "company": {{"text": "<newline-bulleted explanation>"}}
  - "source": {{"url": "<page url>"}}

Context:
  - Competitor: {competitor}
  - URL: {url}
  - Page Type: {page_type}

CRITICAL RULES
  - Output JSON ONLY (no markdown, no commentary).
  - Use ONLY facts from THIS page (no inference/hallucination).
  - If the same product appears multiple times, merge details; conflicting info → add a NOTE bullet.
  - If no products: return "products": {{}}
  - Extract ALL products. Each product must be its own key: <Product Name A>, <Product Name B>, … up to 20. Prioritize core offerings.
  - Include all company and product details that fit schema.
  - If product ownership/partner status is unclear, still include and explain in NOTE.
  - Omit bullets if info not present.
  - Preserve exact wording for names, specs, numbers, certifications.
  - If you are not sure about the product name mention it in the NOTE of that product.

FORMATTING
  - All details are newline-bulleted strings.
  - Each bullet starts with a fixed LABEL + ": ".
  - Allowed product labels: WHAT, CATEGORY, FEATURES, CAPABILITIES (high-level abilities / what the product enables, broader than individual features), USERS, MARKETS, INTEGRATIONS, PRICING, STAGE (alpha, beta, ga, discontinued), SPECS (e.g. weight, dimensions, repeatability, etc.), COMPLIANCE, LINKS, LIMITATIONS (explicit constraints, requirements, or drawbacks), ALIASES, RELEASEDATE, NOTE (caveats not captured elsewhere, e.g. partner product, ownership unclear, image-only info)
  - Allowed company labels:  WHAT, NAME, ALIASES, CONTACT, LOCATION, POSITIONING (how the company describes itself / value proposition), INDUSTRIES, CUSTOMERS, PARTNERS, COMPLIANCE, LINKS, NOTE (caveats not captured elsewhere)

OUTPUT SCHEMA:
{{
  "products": {{
    "Product A": {{
      "text": "WHAT: ... \\nCATEGORY: ... \\nFEATURES: ..."
    }},
    "Product B": {{
      "text": "WHAT: ... \\nCAPABILITIES: ... \\nPRICING: ... \\nSTAGE: ... \\nLINKS: https://... \\nNOTE: ..."
    }}
  }},
  "company": {{
    "text": "NAME: ... \\nCONTACT: ... \\nLOCATION: ... \\nPOSITIONING: ..."
  }},
  "source": {{
    "url": "{url}"
  }}
}}

PAGE TEXT:
{truncated_text}

Return JSON ONLY.
"""
        
        return prompt
    
    def build_stage2a_company_prompt(
        self,
        company_id: str,
        competitor: str,
        company_items: List[Dict[str, Any]]
    ) -> str:
        """Build Stage 2A company consolidation prompt."""
        
        company_items_json = json.dumps(company_items, ensure_ascii=False, indent=2)
        
        prompt = f"""
You are a strict normalizer. Consolidate company information from multiple Stage-1 page outputs and merge the information. All the company information should be from the SAME company.

Input format:
  - "company_id": string (already determined earlier; use as-is)
  - "competitor": string (context only)
  - "items": array of Stage-1 results, each:
    {{
      "company": "<newline-bulleted string from Stage-1>",
      "source": {{"url": "<page url>"}}
    }}

CRITICAL RULES
  - Output JSON ONLY (no markdown, no commentary).
  - Use ONLY facts present in Stage-1 company blocks. Do not invent.
  - If inputs disagree, choose the clearest official info and add a short note in company.notes.
  - If a field is unsupported by inputs, set it to null (or [] for arrays).
  - Extract ALL company information that fit the schema.
  - Extract information ONLY from the main company if there are multiple companies mentioned (the main company should be in line with the URL link).
  - Do not add any other field names to the output than the ones in the proposed output schema.

EXTRACTION
  - name: canonical NAME (prefer homepage/about/contact/legal over blog/press).
  - aliases: union of NAME/ALIASES bullets (dedupe, preserve casing).
  - website: shortest canonical domain for the official site.
  - hq_country: from LOCATION/HQ if explicit; else null.
  - status: only if explicitly stated (active/dormant); else null.
  - tags: up to 3 short keywords from POSITIONING/INDUSTRIES.
  - short_desc: REQUIRED - concise 1-2 sentence description of what the company does (from WHAT/POSITIONING bullets).
  - main_sources_used: include 3–6 URLs actually relied on.
  - notes: optional short conflict/caveat notes.

OUTPUT SCHEMA (including example text):
{{
  "company": {{
    "short_desc": "AI-powered cloud platform for enterprise automation and data analytics.",
    "name": "ExampleCorp",
    "aliases": ["Example", "Example Inc."],
    "status": "active",
    "tags": ["cloud", "ai", "enterprise"],
    "website": "https://example.com",
    "hq_country": "USA",
    "main_sources_used": [
      "https://example.com/about",
      "https://example.com/contact"
    ],
    "notes": ["Some pages list HQ as UK, others as USA."]
  }}
}}

Context competitor: {competitor}

Items:
{company_items_json}

Return JSON ONLY.
"""
        
        return prompt
    
    def build_stage2b_products_prompt(
        self,
        company_id: str,
        products_items: List[Dict[str, Any]]
    ) -> str:
        """Build Stage 2B products consolidation prompt."""
        
        products_items_json = json.dumps(products_items, ensure_ascii=False, indent=2)
        
        prompt = f"""
You are a strict normalizer. Consolidate product information from multiple Stage-1 outputs.

Input format:
  - "company_id": string (from Stage-2A; use as-is)
  - "items": array of Stage-1 results, each:
    {{
      "products": {{"<name>": {{"text": "<bullets>"}}, ...}},
      "source": {{"url": "<page url>"}}
    }}

CRITICAL RULES
  - Output JSON ONLY (no markdown, no commentary).
  - Use ONLY facts present in Stage-1 product text (no invention).
  - Extract ALL products that the company (do not mention products that are not from the company). Each distinct product becomes its own key: <Exact Product Name A>, <Exact Product Name B>, ... up to 20. If >20 exist, include the 20 most prominent (prioritize official/core over incidental mentions).
  - If no products are supported by inputs, return "products": {{}}.
  - Unknown/missing fields → null, [], or {{}} as appropriate.

EXTRACTION (bullet → field mapping)
  - WHAT → short_desc (concise; keep useful brand phrasing)
  - CATEGORY → category
  - FEATURES → tags (split short phrases; lowercase; max 5 total)
  - CAPABILITIES → capabilities (array of objects). Each capability:
      {{
        "name": "string",
        "tags": ["string"],
        "definition": "string" | null
      }}
    (Do NOT auto-add capability tags to product tags.)
  - USERS, MARKETS → markets (union; keep original casing)
  - INTEGRATIONS → specs["integrations"]
  - PRICING → specs["pricing"]
  - STAGE → stage ("alpha" | "beta" | "ga" | "discontinued")
  - SPECS → specs["specs"]
  - COMPLIANCE → compliance (verbatim array of strings if multiple)
  - LINKS → notes
  - ALIASES → notes
  - RELEASEDATE → released_at (ISO granularity if explicit)
  - LIMITATIONS → specs["limitations"]
  - NOTE → notes

FORMATTING RULES
  - Per product include:
    - sources: ["https://...", "https://..."] (URLs actually used for that product)

VOLUME & SELECTION RULES
  - Unify duplicates/merge related info: 
    - Merge related info across items: If information refers to the same product, combine them into one entry!
    - If product names are near-duplicates (e.g., variations, abbreviations), consolidate them under the exact name used on the official page.
      - Conflict resolution: 1. STAGE: choose most conservative (alpha < beta < ga). Any explicit "discontinued" wins. 2. CATEGORY: choose the most specific, concise phrasing.
  - Prioritize sources: When multiple URLs are available, prefer the official product page over incidental mentions, blog posts, or third-party references.

OUTPUT SCHEMA (including example text):
{{
  "products": {{
    "Exact Product Name A": {{
      "name": "Exact Product Name A",
      "category": "string" | null,
      "stage": "alpha" | "beta" | "ga" | "discontinued" | null,
      "markets": ["string"],
      "tags": ["string"],
      "short_desc": "string" | null,
      "product_url": "https://..." | null,
      "docs_url": "https://..." | null,
      "specs": {{}},
      "released_at": "YYYY-MM-DD" | "YYYY-MM" | "YYYY" | null,
      "compliance": ["string"],
      "capabilities": [
        {{
          "name": "string",
          "tags": ["string"],
          "definition": "string" | null
        }}
      ],
      "sources": ["https://...", "https://..."],
      "notes": ["<optional product-level notes>"]
    }},
    "Exact Product Name B": {{
      "name": "Exact Product Name B",
      "category": null,
      "stage": null,
      "markets": [],
      "tags": [],
      "short_desc": null,
      "product_url": null,
      "docs_url": null,
      "specs": {{}},
      "released_at": null,
      "compliance": [],
      "capabilities": [],
      "sources": [],
      "notes": []
    }}
  }}
}}

Context company_id: {company_id}

Items:
{products_items_json}

Return JSON ONLY.
"""
        
        return prompt


class SchemaCompactor:
    """Schema compactor for text truncation."""
    
    def __init__(self):
        self.token_counter = TokenCounter()
    
    def truncate_text(self, text: str, max_tokens: int) -> str:
        """Truncate text to approximate token limit."""
        return self.token_counter.truncate_to_tokens(text, max_tokens)


# Global instances
multi_stage_extractor = MultiStageExtractor()
schema_compactor = SchemaCompactor()


def get_multi_stage_extractor() -> MultiStageExtractor:
    """Get the global multi-stage extractor instance."""
    return multi_stage_extractor


def get_schema_compactor() -> SchemaCompactor:
    """Get the global schema compactor instance."""
    return schema_compactor
